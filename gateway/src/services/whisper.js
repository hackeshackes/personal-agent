/**
 * Whisper ASR Service - è¯­éŸ³è¯†åˆ«æœåŠ¡
 * æ”¯æŒæœ¬åœ° Whisper æˆ– OpenAI Whisper API
 */

const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');

class WhisperService {
  constructor() {
    this.modelPath = process.env.WHISPER_MODEL_PATH || './models/whisper';
    this.useLocal = process.env.WHISPER_LOCAL === 'true';
  }

  /**
   * è½¬å½•éŸ³é¢‘
   */
  async transcribe(audioPath, options = {}) {
    console.log(`ðŸ”„ è½¬å½•ä¸­: ${audioPath}`);

    const {
      language = 'zh',
      model = 'base',
      prompt = ''
    } = options;

    try {
      if (this.useLocal) {
        return await this._transcribeLocal(audioPath, { language, model });
      } else {
        return await this._transcribeAPI(audioPath, { language, prompt });
      }
    } catch (error) {
      console.error('è½¬å½•å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * æœ¬åœ° Whisper è½¬å½•
   */
  async _transcribeLocal(audioPath, options) {
    // ä½¿ç”¨ whisper å‘½ä»¤è¡Œ
    const whisperPath = process.env.WHISPER_PATH || 'whisper';
    
    return new Promise((resolve, reject) => {
      const proc = spawn(whisperPath, [
        audioPath,
        '--model', options.model,
        '--language', options.language,
        '--no_timestamps',
        '--output_format', 'json'
      ]);

      let stdout = '';
      let stderr = '';

      proc.stdout.on('data', (data) => {
        stdout += data.toString();
      });

      proc.stderr.on('data', (data) => {
        stderr += data.toString();
      });

      proc.on('close', (code) => {
        if (code === 0) {
          // è¯»å–è¾“å‡º JSON
          const outputPath = audioPath.replace(/\.[^.]+$/, '.json');
          if (fs.existsSync(outputPath)) {
            const result = JSON.parse(fs.readFileSync(outputPath, 'utf8'));
            resolve({
              text: result.text,
              segments: result.segments,
              language: result.language
            });
          } else {
            resolve({ text: stdout.trim() });
          }
        } else {
          // é™çº§åˆ° API
          this._transcribeAPI(audioPath, options).then(resolve).catch(reject);
        }
      });
    });
  }

  /**
   * OpenAI Whisper API è½¬å½•
   */
  async _transcribeAPI(audioPath, options) {
    const apiKey = process.env.OPENAI_API_KEY;
    
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY not configured');
    }

    const FormData = require('form-data');
    const axios = require('axios');
    
    const form = new FormData();
    form.append('file', fs.createReadStream(audioPath));
    form.append('model', 'whisper-1');
    form.append('language', options.language);
    form.append('response_format', 'verbose_json');

    if (options.prompt) {
      form.append('prompt', options.prompt);
    }

    const response = await axios.post(
      'https://api.openai.com/v1/audio/transcriptions',
      form,
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          ...form.getHeaders()
        },
        timeout: 60000
      }
    );

    return {
      text: response.data.text,
      segments: response.data.segments || [],
      language: response.data.language
    };
  }

  /**
   * å®žæ—¶è½¬å½• (æµå¼)
   */
  async *transcribeStream(audioStream) {
    // TODO: å®žçŽ°æµå¼è½¬å½•
    // ä½¿ç”¨ WebSocket è¿žæŽ¥åˆ° Whisper API
    console.log('ðŸŽ¤ æµå¼è½¬å½•å¯åŠ¨...');
    
    yield { status: 'listening' };
  }

  /**
   * ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å­—å¹•
   */
  async generateSubtitles(audioPath) {
    const result = await this.transcribe(audioPath, { language: 'zh' });
    
    if (result.segments) {
      return result.segments.map(seg => ({
        start: seg.start,
        end: seg.end,
        text: seg.text
      }));
    }
    
    return [];
  }

  /**
   * æ£€æµ‹è¯­è¨€
   */
  async detectLanguage(audioPath) {
    const result = await this.transcribe(audioPath, { 
      language: null // è®©æ¨¡åž‹è‡ªåŠ¨æ£€æµ‹
    });
    return result.language;
  }
}

module.exports = { WhisperService };
